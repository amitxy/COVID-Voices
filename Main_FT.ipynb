{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOF4nowQL1OE"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DueDmL30JR4F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "import matplotlib.ticker as mtick\n",
        "from wordcloud import WordCloud\n",
        "import nltk, re, string, warnings, textwrap, datetime as dt\n",
        "nltk.download('stopwords')\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "from collections import Counter\n",
        "!pip install optuna\n",
        "import optuna, wandb\n",
        "from torch.utils.data import Dataset as DS, DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from huggingface_hub import upload_file, login, notebook_login, HfApi\n",
        "from datasets import Dataset, Features, Sequence, Value\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
        ")\n",
        "from transformers.trainer_callback import TrainerCallback\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB0ec372MC3O"
      },
      "source": [
        "# Setting Up GPU connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR7SL-rvL-7g"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA62fR3vNZHT"
      },
      "source": [
        "# Generic \"Full-Code\" Fine-Tuning (Change names when comments say so)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVm9AdrNNhRW"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oftwCUnNdXP"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"Data\"\n",
        "PREPROCESS_VERSION = \"\"   # change to 1,2 or 3 for other preprocessing versions\n",
        "train_df = pd.read_csv(f\"{DATA_DIR}/Corona_NLP_train{PREPROCESS_VERSION}.csv\", encoding=\"latin-1\")\n",
        "test_df  = pd.read_csv(f\"{DATA_DIR}/Corona_NLP_test{PREPROCESS_VERSION}.csv\",  encoding=\"latin-1\")\n",
        "\n",
        "train_df = train_df.rename(columns={\"OriginalTweet\":\"text\", \"Sentiment\":\"label\"})\n",
        "test_df  = test_df.rename(columns={\"OriginalTweet\":\"text\", \"Sentiment\":\"label\"})\n",
        "\n",
        "label_map = {'Extremely Negative':0,'Negative':1,'Neutral':2,\n",
        "             'Positive':3,'Extremely Positive':4}\n",
        "\n",
        "train_df[\"label\"] = train_df.label.map(label_map).astype(int)\n",
        "test_df[\"label\"]  = test_df.label.map(label_map).astype(int)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzlTl3-6OBqq"
      },
      "outputs": [],
      "source": [
        "train_df, eval_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Eval size:\", len(eval_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRe2TY_xO8Af"
      },
      "source": [
        "## Defining the custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXKfI5L8O8Ai"
      },
      "outputs": [],
      "source": [
        "class TweetDataset(DS):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "      self.texts = dataframe['text'].tolist()\n",
        "      self.labels = dataframe['label'].tolist()\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
        "        return_dict = {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "        return return_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpAMA86bO8Ai"
      },
      "source": [
        "## Early-stopping helping function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTIst5eYO8Ai"
      },
      "outputs": [],
      "source": [
        "def early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, current_val_accuracy, current_val_accuracy_epoch):\n",
        "    early_stop_flag = False\n",
        "    if current_val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = current_val_accuracy\n",
        "        best_val_accuracy_epoch = current_val_accuracy_epoch\n",
        "    else:\n",
        "        if current_val_accuracy_epoch - best_val_accuracy_epoch > patience:\n",
        "            early_stop_flag = True\n",
        "    return best_val_accuracy, best_val_accuracy_epoch, early_stop_flag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9IBH1PIO8Aj"
      },
      "source": [
        "## Main training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xtBPjnIO8Aj"
      },
      "outputs": [],
      "source": [
        "def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial, hf_repo_id, hf_folder):\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_accuracy_epoch = 0\n",
        "    early_stop_flag = False\n",
        "    best_model_state = None\n",
        "    model_save_path = \"best_model.pt\"\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train() # Enable training mode\n",
        "        train_loss = 0.0\n",
        "        total_train_samples = 0\n",
        "        correct_train_predictions = 0\n",
        "\n",
        "        for batch in train_loader: #Iterates over the train_loader, which is a DataLoader object containing batches of training data.\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad() # Reset gradients\n",
        "            outputs = model(input_ids, attention_mask=attention_mask) # Forward pass\n",
        "            logits = outputs.logits # save the logits (the raw output of the model)\n",
        "            loss = criterion(logits, labels) # Calculate loss\n",
        "\n",
        "            loss.backward() # Backward pass\n",
        "            optimizer.step() # Update weights using the optimizer\n",
        "\n",
        "            # Accumulate training loss and predictions\n",
        "            train_loss += loss.item() * input_ids.size(0)\n",
        "            total_train_samples += input_ids.size(0)\n",
        "            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        train_loss /= total_train_samples\n",
        "        train_accuracy = correct_train_predictions / total_train_samples\n",
        "\n",
        "        ###  Validation loop  ###\n",
        "        model.eval() # Enable evaluation mode\n",
        "        val_loss = 0.0\n",
        "        total_val_samples = 0\n",
        "        correct_val_predictions = 0\n",
        "\n",
        "        all_val_labels = []\n",
        "        all_val_preds = []\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient computation\n",
        "            for batch in val_loader: # iterate on the val_loader's batches\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                val_loss += loss.item() * input_ids.size(0)\n",
        "                total_val_samples += input_ids.size(0)\n",
        "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "                all_val_labels.extend(labels.cpu().numpy())\n",
        "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "\n",
        "        # calculate metrics\n",
        "        val_loss /= total_val_samples\n",
        "        val_accuracy = correct_val_predictions / total_val_samples\n",
        "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted')\n",
        "        val_recall = recall_score(all_val_labels, all_val_preds, average='weighted')\n",
        "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
        "\n",
        "        # Check for early stopping\n",
        "        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch)\n",
        "\n",
        "        # Save the best model under the best_model_state parameter\n",
        "        if val_accuracy == best_val_accuracy:\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "        # Log metrics to Weights & Biases - THIS IS WHERE WE TRACK THE RESULTS AND THE PROCESS\n",
        "        wandb.log({ #log == logging of the training process (e.g. results) - will be done each epoch\n",
        "            \"Epoch\": epoch,\n",
        "            \"Train Loss\": train_loss,\n",
        "            \"Train Accuracy\": train_accuracy,\n",
        "            \"Validation Loss\": val_loss,\n",
        "            \"Validation Accuracy\": val_accuracy,\n",
        "            \"Validation Precision\": val_precision,\n",
        "            \"Validation Recall\": val_recall,\n",
        "            \"Validation F1\": val_f1})\n",
        "\n",
        "        if early_stop_flag:  # Checks whether the early stopping condition has been met, as indicated by the early_stop_flag\n",
        "            break# Exits the training loop immediately if the early stopping condition is satisfied\n",
        "\n",
        "    if best_model_state is not None:\n",
        "      torch.save(best_model_state, model_save_path) # Save locally\n",
        "      # Push the best model to Hugging Face Hub\n",
        "      try:\n",
        "          upload_file(\n",
        "              path_or_fileobj=model_save_path,\n",
        "              path_in_repo=f\"{hf_folder}/best_model_trial_{trial.number}.pt\",\n",
        "              repo_id=hf_repo_id,\n",
        "              commit_message=f\"Upload best model from trial {trial.number}\",\n",
        "              token = \"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\"\n",
        "          )\n",
        "          print(f\"Successfully pushed best model of trial {trial.number} to {hf_repo_id}\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error pushing model to Hugging Face Hub: {e}\")\n",
        "\n",
        "\n",
        "    return best_val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fki6GXYfO8Ak"
      },
      "source": [
        "## Optuna objective function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o3DdsxKO8Ak"
      },
      "outputs": [],
      "source": [
        "# Objective Function for Optuna\n",
        "def objective(trial, hf_repo_id, model_name, wandb_project_name, hf_folder):\n",
        "    # Hyperparameter suggestions\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4)\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
        "    patience = trial.suggest_int(\"patience\", 2, 5)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 0, 2)\n",
        "    max_len = trial.suggest_categorical(\"max_len\", [64, 128])\n",
        "    classifier_dropout = trial.suggest_float(\"dropout_prob\", 0.1, 0.5) # Adding the classifier's dropout as a HP (original was 0.1)\n",
        "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.0, 0.2) # Adding label smoothing as a HP\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True) # initialize the model from HF, num_labels=5 since we have 5 classes (EDA).\n",
        "    model.classifier.dropout = nn.Dropout(classifier_dropout) # Set the dropout rate\n",
        "    model = model.to(device)\n",
        "\n",
        "    train_dataset = TweetDataset(train_df, tokenizer, max_len) # Create the TweetDataset object\n",
        "    val_dataset = TweetDataset(eval_df, tokenizer, max_len) # Create the TweetDataset object\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # insert into a DataLoader\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # insert into a DataLoader\n",
        "\n",
        "    for param in model.deberta.parameters():    # Freeze layers\n",
        "        param.requires_grad = False\n",
        "    for param in model.deberta.encoder.layer[len(model.deberta.encoder.layer)-num_layers:].parameters():     # unfreeze the last \"num_layers\" of the encoder\n",
        "        param.requires_grad = True\n",
        "    for param in model.classifier.parameters():    #unfreeze the classifier\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Initialize Weights & Biases - the values in the config are the properties of each trial.\n",
        "    wandb.init(project=wandb_project_name,\n",
        "               config={\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"patience\": patience,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"num_layers\": num_layers,\n",
        "        \"max_len\": max_len,\n",
        "        \"classifier_drouput\": classifier_dropout,\n",
        "        \"label_smoothing\": label_smoothing,\n",
        "        \"architecture\": model_name},\n",
        "        name=f\"trial_{trial.number}\") # The name that will be saved in the W&B platform\n",
        "\n",
        "    # Train the model and get the best validation accuracy\n",
        "    best_val_accuracy = train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs=20, patience=patience, trial=trial, hf_repo_id=hf_repo_id, hf_folder=hf_folder)\n",
        "\n",
        "    wandb.finish() # Finish the Weights & Biases run\n",
        "\n",
        "    return best_val_accuracy # Return best validation acc as the objective to maximize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4pIjwDDO8Al"
      },
      "source": [
        "## Optuna Study aiming at maximizing model's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tc4iaM7O8Al"
      },
      "outputs": [],
      "source": [
        "hf_repo_id = \"CarmelKron/ADV_DL_Project\"    # repo ID\n",
        "model_name = \"microsoft/deberta-v3-base\"    # Change to cardiffnlp/twitter-roberta-base-sentiment-latest to run the Twitter-RoBERTa model\n",
        "wandb_project_name = \"DeBERTa-v3-base_FT_Full\"    # Change accordingly\n",
        "hf_folder = \"Full_FT_DeBERTa-v3-base\"   # Change accordingly\n",
        "# Optuna Study\n",
        "study = optuna.create_study(direction=\"maximize\")  # Specifies that the goal of the optimization is to maximize the objective function\n",
        "study.optimize(lambda trial: objective(trial, hf_repo_id, model_name, wandb_project_name, hf_folder), n_trials=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weCWRhrbUC6j"
      },
      "source": [
        "# Generic HF Fine-Tuning (Change names when comments say so)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNDSd2awUQoM"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs2bG_JpUSrF"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"Data\"\n",
        "PREPROCESS_VERSION = \"\"   # change to 1,2 or 3 for other preprocessing versions\n",
        "train_df = pd.read_csv(f\"{DATA_DIR}/Corona_NLP_train{PREPROCESS_VERSION}.csv\", encoding=\"latin-1\")\n",
        "test_df  = pd.read_csv(f\"{DATA_DIR}/Corona_NLP_test{PREPROCESS_VERSION}.csv\",  encoding=\"latin-1\")\n",
        "\n",
        "if PREPROCESS_VERSION == 3:\n",
        "  # Count rows where the 'Narratives' column is not an empty list\n",
        "  non_empty_narratives_count = train_df[train_df['Narratives'] != '[]'].shape[0]\n",
        "  print(f\"Number of rows with non-empty narratives: {non_empty_narratives_count}\")\n",
        "\n",
        "train_df = train_df.rename(columns={\"OriginalTweet\":\"text\", \"Sentiment\":\"label\"})\n",
        "test_df  = test_df.rename(columns={\"OriginalTweet\":\"text\", \"Sentiment\":\"label\"})\n",
        "\n",
        "label_map = {'Extremely Negative':0,'Negative':1,'Neutral':2,\n",
        "             'Positive':3,'Extremely Positive':4}\n",
        "\n",
        "train_df[\"label\"] = train_df.label.map(label_map).astype(int)\n",
        "test_df[\"label\"]  = test_df.label.map(label_map).astype(int)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3vD1AX-USrJ"
      },
      "outputs": [],
      "source": [
        "train_df, eval_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Eval size:\", len(eval_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyJS3cxMUVtS"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1aEVclIUKiP"
      },
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "os.environ[\"WANDB_PROJECT\"] = \"HF_FT_Carmel_Orig_Data\"    # Change accordingly\n",
        "wandb.login()\n",
        "model_ckpt = \"microsoft/deberta-v3-base\"    # Change to cardiffnlp/twitter-roberta-base-sentiment-latest to run the Twitter-RoBERTa model\n",
        "\n",
        "# Keep raw datasets (we'll tokenize per trial)\n",
        "train_raw_ds = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
        "eval_raw_ds  = Dataset.from_pandas(eval_df[[\"text\", \"label\"]])\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
        "    }\n",
        "\n",
        "optuna_trial = None\n",
        "\n",
        "def model_init():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=5, ignore_mismatched_sizes=True)\n",
        "    return model\n",
        "\n",
        "def optuna_objective(trial, wandb_project_name, hf_repo_id, hf_folder):\n",
        "    global optuna_trial\n",
        "    optuna_trial = trial\n",
        "\n",
        "    # Sample hyperparameters\n",
        "    max_len = trial.suggest_categorical(\"max_seq_length\", [64, 128])\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-6, 1e-4, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.3)\n",
        "    batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64])\n",
        "    warmup_ratio  = trial.suggest_float(\"warmup_ratio\", 0.01, 0.2)\n",
        "    lr_scheduler_type = trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\"])\n",
        "    adam_beta1 = trial.suggest_float(\"adam_beta1\", 0.85, 0.95)\n",
        "    adam_beta2 = trial.suggest_float(\"adam_beta2\", 0.98, 0.999)\n",
        "    adam_epsilon = trial.suggest_float(\"adam_epsilon\", 1e-8, 1e-6, log=True)\n",
        "    label_smoothing_factor = trial.suggest_float(\"label_smoothing_factor\", 0.0, 0.2)\n",
        "    gradient_accumulation_steps = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4])\n",
        "\n",
        "\n",
        "    # Tokenize per trial\n",
        "    def tokenize(batch):\n",
        "        return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "\n",
        "    train_ds = train_raw_ds.map(tokenize, batched=True)\n",
        "    eval_ds  = eval_raw_ds.map(tokenize, batched=True)\n",
        "    train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "    eval_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "    output_dir = f\"./trial_{trial.number}\"\n",
        "    args = TrainingArguments(\n",
        "        lr_scheduler_type=lr_scheduler_type,\n",
        "        adam_beta1=adam_beta1,\n",
        "        adam_beta2=adam_beta2,\n",
        "        adam_epsilon=adam_epsilon,\n",
        "        label_smoothing_factor=label_smoothing_factor,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        output_dir=output_dir,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=20,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"best\",\n",
        "        load_best_model_at_end=True,\n",
        "        save_total_limit=1,\n",
        "        metric_for_best_model=\"eval_accuracy\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        report_to=\"wandb\",\n",
        "        disable_tqdm=False,\n",
        "        run_name=f\"trial_{trial.number}\"\n",
        "    )\n",
        "\n",
        "    wandb.init(\n",
        "    project=wandb_project_name,\n",
        "    name=f\"trial_{trial.number}\",\n",
        "    reinit=\"finish_previous\",\n",
        ")\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model_init=model_init,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=eval_ds,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4),]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # Push manually\n",
        "    api = HfApi()\n",
        "    api.upload_folder(\n",
        "              folder_path=output_dir,\n",
        "              path_in_repo=f\"./{hf_folder}/trial_{trial.number}\",\n",
        "              repo_id=hf_repo_id,\n",
        "              commit_message=f\"Upload best model from trial {trial.number}\",\n",
        "              repo_type=\"model\",\n",
        "              token = \"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\"\n",
        "          )\n",
        "\n",
        "    return trainer.evaluate()[\"eval_accuracy\"]\n",
        "\n",
        "wandb_project_name = \"HF_FT_Carmel_Orig_Data\"   # Change accordingly\n",
        "hf_repo_id = \"CarmelKron/ADV_DL_Project\"    # repo ID\n",
        "hf_folder = \"HF_FT_Carmel_Orig_Data\"   # Change accordingly\n",
        "\n",
        "# Run Optuna\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(lambda trial: optuna_objective(trial, wandb_project_name, hf_repo_id, hf_folder), n_trials=15)\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "# Print all trials summary\n",
        "print(\"All trial results:\")\n",
        "for t in study.trials:\n",
        "    print(f\"Trial {t.number} — Accuracy: {t.value:.4f} — Params: {t.params}\")\n",
        "print(f\"\\n✅ Best Trial: {study.best_trial.number} — Accuracy: {study.best_value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPdGVmBx41bJskMV9AHWSfm",
      "collapsed_sections": [
        "aOF4nowQL1OE",
        "pB0ec372MC3O",
        "weCWRhrbUC6j"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "mount_file_id": "17Y-B02SXw-CwQtrh_rDbnB82oUFC-6Lu",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
