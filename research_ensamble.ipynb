{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c0234d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "from covid_voices.data.corona_dataset import CoronaTweetDataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d274e0",
   "metadata": {},
   "source": [
    "## Some Examples of usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c22ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets:\n",
      "dict_keys(['train', 'val', 'test'])\n",
      "\n",
      "See the preprocess_tweet function in action :\n",
      "\"consumer voice has compiled a list of creative ideas and best practices for staying connected during the pandemic.  the list includes ways to communicate with loved ones and ideas for staying active and engaged while in isolation.\"\n",
      "\n",
      "https://t.co/j9udncqlnn https://t.co/kwrrsjhfkq\n"
     ]
    }
   ],
   "source": [
    "def preprocess_tweet(text):\n",
    "        \"\"\"Clean and normalize tweet text\"\"\"\n",
    "        # Example preprocessing - you can expand this\n",
    "        text = text.lower()\n",
    "        text = text.replace('#', 'hashtag_')\n",
    "        text = text.replace('@', 'mention_')\n",
    "        return text\n",
    "\n",
    "\n",
    "# Load datasets with preprocessing and split into train, validation, test\n",
    "datasets = CoronaTweetDataset.load_datasets(preprocessing=preprocess_tweet, \n",
    "                                            is_val_split=True,\n",
    "                                            val_size=0.2,\n",
    "                                            seed=SEED)\n",
    "\n",
    "print(f\"Loaded datasets:\\n{datasets.keys()}\\n\")\n",
    "print(f'See the preprocess_tweet function in action :\\n{datasets[\"train\"][0][\"text\"]}')\n",
    "\n",
    "\n",
    "# split in train, validation, test\n",
    "train_dataset = datasets[\"train\"]\n",
    "val_dataset = datasets[\"val\"]\n",
    "test_dataset = datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124fc68",
   "metadata": {},
   "source": [
    "## Using HF libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1b5551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815667aaec9c4ffa9d8fdd4e17e14454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32925 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334c3e1f4c8c47f3b9d395fee3c0256e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b007736191c4ca784528e3587703a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "output_base_dir = \"./models/\"\n",
    "project_name = \"corona-NLP-ensemble\"\n",
    "batch_size = 128\n",
    "max_length = 280 # max length of the tweet\n",
    "\n",
    "\n",
    "def make_tokenizer(model_name, max_length=512):\n",
    "    \"\"\"Factory function to create a tokenizer function\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    def tokenize(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "\n",
    "tokenize_function = make_tokenizer(model_name, max_length)\n",
    "\n",
    "\n",
    "# Apply to all datasets\n",
    "tokenized_datasets = hf_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=hf_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ded8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    "metrics = [evaluate.load(name) for name in metric_names]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    results = {}\n",
    "    for metric in metrics:\n",
    "        # Some metrics (like f1) require average=\"macro\" for multiclass\n",
    "        if metric.name in [\"f1\", \"precision\", \"recall\"]:\n",
    "            res = metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "        else:\n",
    "            res = metric.compute(predictions=predictions, references=labels)\n",
    "        results.update(res)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab90a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = (predictions == labels).astype(float).mean().item()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ff314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=train_dataset.num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test_output\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=128,\n",
    "    num_train_epochs=5,\n",
    "    do_train=True,\n",
    "    do_eval=True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.init(project=project_name, name=model_name, reinit=True)\n",
    "trainer.train()\n",
    "trainer.save_model(os.path.join(output_base_dir, model_name))\n",
    "tokenizer.save_pretrained(os.path.join(output_base_dir, model_name))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21a26b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
