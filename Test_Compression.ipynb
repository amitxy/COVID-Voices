{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "996rKvAE_R6R",
        "HN9GgOGp_vTQ",
        "aA4eRlB4HwcV",
        "TVgKFr9W_w69",
        "Pqx-G_EpOZJ_"
      ],
      "mount_file_id": "10RRmXjXo8FeOpz1Whuip24_hZ2YHFLAQ",
      "authorship_tag": "ABX9TyNywC0Po4RwM2YSkgRolbS1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91ad11a4a23241dab2de072734727a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be1a608b45534d44b1ecc590615832cc",
              "IPY_MODEL_a151eba1d2ef4b49868af284477847be",
              "IPY_MODEL_10fbb2a652474e519148ff3d356f5c1d"
            ],
            "layout": "IPY_MODEL_ade1c71e054f47f5a25a3d272894d548"
          }
        },
        "be1a608b45534d44b1ecc590615832cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b597cf6d6b54085b9c12f497f35779c",
            "placeholder": "​",
            "style": "IPY_MODEL_f771ce1d2dba4a5a90c0c6c522678109",
            "value": "Fetching 2 files: 100%"
          }
        },
        "a151eba1d2ef4b49868af284477847be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_236a99239b4b480c8da16b46b8d9f1a1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7baf5b14d45465b923fe23636265a71",
            "value": 2
          }
        },
        "10fbb2a652474e519148ff3d356f5c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93e9423a8ce242678691cd109fa708bd",
            "placeholder": "​",
            "style": "IPY_MODEL_c88a4a85483547488884fd38306e7066",
            "value": " 2/2 [00:00&lt;00:00,  4.08it/s]"
          }
        },
        "ade1c71e054f47f5a25a3d272894d548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b597cf6d6b54085b9c12f497f35779c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f771ce1d2dba4a5a90c0c6c522678109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "236a99239b4b480c8da16b46b8d9f1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7baf5b14d45465b923fe23636265a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93e9423a8ce242678691cd109fa708bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88a4a85483547488884fd38306e7066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42c52558d20445f595fb33e22a4e2675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_272684a539664820abc4d3f1cbced5df",
              "IPY_MODEL_b9c7296c93454cb2b225523a669645dc",
              "IPY_MODEL_f05acc876d9741e39ab2685c6d1d1a92"
            ],
            "layout": "IPY_MODEL_b449721a02434b85b8b087b338dfb2df"
          }
        },
        "272684a539664820abc4d3f1cbced5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da335b0cab1b42c595f934627b16ddd3",
            "placeholder": "​",
            "style": "IPY_MODEL_468a0fdd675d4324ad5d967392fe4bb5",
            "value": "config.json: "
          }
        },
        "b9c7296c93454cb2b225523a669645dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0bb55f07f4242789beb59f1574b5512",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a497b35de9a4a7fa216d5bdda01157b",
            "value": 1
          }
        },
        "f05acc876d9741e39ab2685c6d1d1a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761cfc6a7a5043de971df22f6ad82acf",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e94163dda24fba8ed69d1bffc8c3ff",
            "value": " 1.08k/? [00:00&lt;00:00, 111kB/s]"
          }
        },
        "b449721a02434b85b8b087b338dfb2df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da335b0cab1b42c595f934627b16ddd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468a0fdd675d4324ad5d967392fe4bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0bb55f07f4242789beb59f1574b5512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3a497b35de9a4a7fa216d5bdda01157b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "761cfc6a7a5043de971df22f6ad82acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e94163dda24fba8ed69d1bffc8c3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638b17c581f247b5a3e9dd5a7576d0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad2cccbd76f045d293e469803d6dd4fd",
              "IPY_MODEL_77e393772c144a0f9deadb3d64571c6e",
              "IPY_MODEL_88332f787895410e88f6f6c33f67f169"
            ],
            "layout": "IPY_MODEL_be7d27cab0144dd597b6547487721e7b"
          }
        },
        "ad2cccbd76f045d293e469803d6dd4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb965a57de04d8a8ef33c7ce6325667",
            "placeholder": "​",
            "style": "IPY_MODEL_ba686b582e8b40789aab1e4867356cbe",
            "value": "Fetching 2 files: 100%"
          }
        },
        "77e393772c144a0f9deadb3d64571c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe2905ef0a4460ab34c83b25f6313a2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e25ea8aa3ddf4262aa659324158004c2",
            "value": 2
          }
        },
        "88332f787895410e88f6f6c33f67f169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ea377db7754699bc9728e3238f502b",
            "placeholder": "​",
            "style": "IPY_MODEL_58b99f37814c4b7abdd285e49159c516",
            "value": " 2/2 [00:00&lt;00:00,  4.12it/s]"
          }
        },
        "be7d27cab0144dd597b6547487721e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb965a57de04d8a8ef33c7ce6325667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba686b582e8b40789aab1e4867356cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe2905ef0a4460ab34c83b25f6313a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e25ea8aa3ddf4262aa659324158004c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84ea377db7754699bc9728e3238f502b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b99f37814c4b7abdd285e49159c516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd18220e80b740e08193aa8fed8d7d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a973a0418e5455790434be854fa25d9",
              "IPY_MODEL_224b80985ed74650abec60e2ceea4035",
              "IPY_MODEL_5164ae0c850e4aaeaf41fe5f13acca29"
            ],
            "layout": "IPY_MODEL_0f14da2276d740219c9102dc9f42d0f0"
          }
        },
        "4a973a0418e5455790434be854fa25d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d835b37925d44aea7f611ce362c385b",
            "placeholder": "​",
            "style": "IPY_MODEL_7d195d8836864fb1b1267b3a96bc6407",
            "value": "Fetching 2 files: 100%"
          }
        },
        "224b80985ed74650abec60e2ceea4035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725c6063f3374d7a9239d7db0cf52d6b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b257f597f27e4dddaf5269c15306b4b0",
            "value": 2
          }
        },
        "5164ae0c850e4aaeaf41fe5f13acca29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b7a969f2da4550b97b031fdec16de7",
            "placeholder": "​",
            "style": "IPY_MODEL_d2013a94766841868f3d0ed2f3f2efc1",
            "value": " 2/2 [00:00&lt;00:00, 234.82it/s]"
          }
        },
        "0f14da2276d740219c9102dc9f42d0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d835b37925d44aea7f611ce362c385b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d195d8836864fb1b1267b3a96bc6407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "725c6063f3374d7a9239d7db0cf52d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b257f597f27e4dddaf5269c15306b4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13b7a969f2da4550b97b031fdec16de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2013a94766841868f3d0ed2f3f2efc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e1d0516c7324378b471aeecd50e8b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de92d7edb59749fdacf15ce8fd61a18f",
              "IPY_MODEL_ceb8dfc0a9374360bbd45d7dc5d0d6b3",
              "IPY_MODEL_5997fa1ba794499fb820360e3076655c"
            ],
            "layout": "IPY_MODEL_fd5fafc429d6467e9d98caa9ae0ad00d"
          }
        },
        "de92d7edb59749fdacf15ce8fd61a18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f24edc978c04457928274fc039d416a",
            "placeholder": "​",
            "style": "IPY_MODEL_953f7b4c431d412b9c075951114f1ead",
            "value": "Fetching 2 files: 100%"
          }
        },
        "ceb8dfc0a9374360bbd45d7dc5d0d6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9847f40287d34f3e830f7fc78d526eaa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4f7d40a10b245bcab8d88d253009e29",
            "value": 2
          }
        },
        "5997fa1ba794499fb820360e3076655c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e838efed1864eac88869e02aceddd58",
            "placeholder": "​",
            "style": "IPY_MODEL_ac19118900e5466fa14a5d8d9d0a4b20",
            "value": " 2/2 [00:00&lt;00:00,  4.34it/s]"
          }
        },
        "fd5fafc429d6467e9d98caa9ae0ad00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f24edc978c04457928274fc039d416a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953f7b4c431d412b9c075951114f1ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9847f40287d34f3e830f7fc78d526eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f7d40a10b245bcab8d88d253009e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e838efed1864eac88869e02aceddd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac19118900e5466fa14a5d8d9d0a4b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "996rKvAE_R6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U bitsandbytes accelerate transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY0LPxP6KU3K",
        "outputId": "37585e84-4c65-4793-c6f3-374592e48643"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.3)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "import pandas as pd\n",
        "import tempfile, shutil\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import BitsAndBytesConfig, AutoConfig\n",
        "from huggingface_hub import hf_hub_download, snapshot_download\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from safetensors.torch import load_file as load_safetensors\n",
        "    SAFE_AVAILABLE = True\n",
        "except Exception:\n",
        "    SAFE_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from transformers import BitsAndBytesConfig\n",
        "    BNB_AVAILABLE = True\n",
        "except Exception:\n",
        "    BNB_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from torch.nn.utils import prune\n",
        "    PRUNE_AVAILABLE = True\n",
        "except Exception:\n",
        "    PRUNE_AVAILABLE = False\n",
        "\n",
        "import torch.nn as nn\n",
        "try:\n",
        "    # PyTorch 2.x preferred path\n",
        "    from torch.ao.quantization import quantize_dynamic as ao_quantize_dynamic\n",
        "    _HAS_AO_Q = True\n",
        "except Exception:\n",
        "    _HAS_AO_Q = False\n",
        "try:\n",
        "    # Fallback (older PyTorch)\n",
        "    from torch.quantization import quantize_dynamic as legacy_quantize_dynamic\n",
        "    _HAS_LEGACY_Q = True\n",
        "except Exception:\n",
        "    _HAS_LEGACY_Q = False"
      ],
      "metadata": {
        "id": "2tM1AlJs_t9e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generic Compression Class"
      ],
      "metadata": {
        "id": "HN9GgOGp_vTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class CompressConfig:\n",
        "    model_id: str = \"microsoft/deberta-v3-base\"\n",
        "    weights_path: str = \"checkpoint_dir_or_file\"  # can be FOLDER or FILE\n",
        "    num_labels: Optional[int] = None\n",
        "    max_len: int = 128\n",
        "    batch_size: int = 32\n",
        "    prune_amount: float = 0.40\n",
        "    do_quantized: bool = True\n",
        "    do_pruned: bool = True\n",
        "    do_kd: bool = True\n",
        "    kd_student_id: str = \"distilbert-base-uncased\"\n",
        "    kd_epochs: int = 2\n",
        "    kd_alpha: float = 0.7\n",
        "    kd_T: float = 2.0\n",
        "    # NEW:\n",
        "    quantization_backend: str = \"dynamic\"  # \"dynamic\" or \"bnb\"\n",
        "    force_cpu_for_all: bool = False        # set True to time every model on CPU (fair vs dynamic int8)\n",
        "\n",
        "\n",
        "class CompressionComparator:\n",
        "    \"\"\"\n",
        "    Compare Original / 8-bit Quantized / Pruned (/ KD student if train_df is provided)\n",
        "    on (accuracy, weighted F1, params, nonzero params, requires_training, checkpoint size MB).\n",
        "    Supports:\n",
        "      - HF folder (config.json + pytorch_model.bin/model.safetensors)\n",
        "      - Folder with config.json + custom filename (e.g., best_model.pt) via state_dict=\n",
        "      - Single weight file path (no config) -> builds from self.cfg.model_id and loads state_dict\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg: CompressConfig):\n",
        "        self.cfg = cfg\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.amp_dtype = (\n",
        "            torch.bfloat16\n",
        "            if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "            else torch.float16\n",
        "        )\n",
        "\n",
        "    # ------------- FS helpers -------------\n",
        "    def _file_size_mb(self, path: str) -> Optional[float]:\n",
        "        return os.path.getsize(path) / (1024**2) if os.path.exists(path) else None\n",
        "\n",
        "    def _dir_size_mb(self, path: str) -> float:\n",
        "        total = 0\n",
        "        for root, _, files in os.walk(path):\n",
        "            for f in files:\n",
        "                total += os.path.getsize(os.path.join(root, f))\n",
        "        return total / (1024**2)\n",
        "\n",
        "    def _save_pretrained_and_measure_mb(self, model) -> float:\n",
        "        tmpdir = tempfile.mkdtemp(prefix=\"ckpt_tmp_\")\n",
        "        try:\n",
        "            model.save_pretrained(tmpdir, safe_serialization=True)\n",
        "            return self._dir_size_mb(tmpdir)\n",
        "        finally:\n",
        "            shutil.rmtree(tmpdir, ignore_errors=True)\n",
        "\n",
        "    def _save_state_dict_and_measure_mb(self, model) -> float:\n",
        "        tmpf = tempfile.NamedTemporaryFile(delete=False, suffix=\".pt\")\n",
        "        tmpf.close()\n",
        "        try:\n",
        "            model_cpu = model.to(\"cpu\")\n",
        "            torch.save(model_cpu.state_dict(), tmpf.name)\n",
        "            return self._file_size_mb(tmpf.name)\n",
        "        finally:\n",
        "            try:\n",
        "                os.remove(tmpf.name)\n",
        "            except OSError:\n",
        "                pass\n",
        "\n",
        "    # ------------- Loading logic (key upgrade) -------------\n",
        "    def _has_tokenizer_files(self, folder: str) -> bool:\n",
        "      # Any of these indicate a tokenizer is present\n",
        "      candidates = [\n",
        "          \"tokenizer.json\",\n",
        "          \"tokenizer_config.json\",\n",
        "          \"special_tokens_map.json\",\n",
        "          \"vocab.txt\",          # BERT/WordPiece\n",
        "          \"merges.txt\",         # BPE\n",
        "          \"vocab.json\",         # BPE/Roberta-style\n",
        "          \"spiece.model\",       # SentencePiece\n",
        "      ]\n",
        "      return any(os.path.exists(os.path.join(folder, f)) for f in candidates)\n",
        "\n",
        "    def _is_dir(self, p: str) -> bool:\n",
        "        return os.path.isdir(p)\n",
        "\n",
        "    def _has_config(self, folder: str) -> bool:\n",
        "        return os.path.exists(os.path.join(folder, \"config.json\"))\n",
        "\n",
        "    def _find_weight_file_in_dir(self, folder: str) -> Optional[str]:\n",
        "        # Prefer standard HF names; else common custom ones (like best_model.pt)\n",
        "        prefs = [\"model.safetensors\", \"pytorch_model.bin\", \"best_model.safetensors\", \"best_model.bin\", \"best_model.pt\"]\n",
        "        for name in prefs:\n",
        "            cand = os.path.join(folder, name)\n",
        "            if os.path.exists(cand):\n",
        "                return cand\n",
        "        # Fallback: any .safetensors / .bin / .pt\n",
        "        for fname in os.listdir(folder):\n",
        "            if fname.endswith((\".safetensors\", \".bin\", \".pt\")):\n",
        "                return os.path.join(folder, fname)\n",
        "        return None\n",
        "\n",
        "    def _load_state_dict_from_path(self, path: str) -> Dict[str, torch.Tensor]:\n",
        "        if path.endswith(\".safetensors\") and SAFE_AVAILABLE:\n",
        "            return load_safetensors(path)\n",
        "        return torch.load(path, map_location=\"cpu\")\n",
        "\n",
        "    def _build_from_folder_maybe_custom_weights(self, folder: str, num_labels: int):\n",
        "      # Tokenizer: prefer folder if present; else fall back to base model_id\n",
        "      if self._has_tokenizer_files(folder):\n",
        "          tok = AutoTokenizer.from_pretrained(folder)\n",
        "      else:\n",
        "          tok = AutoTokenizer.from_pretrained(self.cfg.model_id)\n",
        "\n",
        "      # If standard HF filenames exist, use from_pretrained directly\n",
        "      std_files = [\"pytorch_model.bin\", \"model.safetensors\"]\n",
        "      if any(os.path.exists(os.path.join(folder, f)) for f in std_files):\n",
        "          model = AutoModelForSequenceClassification.from_pretrained(\n",
        "              folder, num_labels=num_labels, ignore_mismatched_sizes=True\n",
        "          )\n",
        "          return model, tok\n",
        "\n",
        "      # Otherwise, look for a custom weight file (e.g., best_model.pt)\n",
        "      wpath = self._find_weight_file_in_dir(folder)\n",
        "      if wpath is None:\n",
        "          # No weights in folder -> init from config only (random init)\n",
        "          model = AutoModelForSequenceClassification.from_pretrained(\n",
        "              folder, num_labels=num_labels, ignore_mismatched_sizes=True\n",
        "          )\n",
        "          return model, tok\n",
        "\n",
        "      # NEW: build from config, then load your custom state_dict\n",
        "      config = AutoConfig.from_pretrained(folder)\n",
        "      # ensure num_labels matches what you want to run with\n",
        "      if getattr(config, \"num_labels\", None) != num_labels:\n",
        "          config.num_labels = num_labels\n",
        "\n",
        "      model = AutoModelForSequenceClassification.from_config(config)\n",
        "      state = self._load_state_dict_from_path(wpath)\n",
        "      missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "      if missing or unexpected:\n",
        "          print(\"[Folder custom weights] missing:\", missing, \"unexpected:\", unexpected)\n",
        "\n",
        "      return model, tok\n",
        "\n",
        "    def _build_from_single_file(\n",
        "        self, file_path: str, num_labels: int\n",
        "    ) -> Tuple[torch.nn.Module, AutoTokenizer]:\n",
        "        \"\"\"\n",
        "        Single weight file: build from base model_id config and load state_dict into it.\n",
        "        \"\"\"\n",
        "        tok = AutoTokenizer.from_pretrained(self.cfg.model_id)\n",
        "        # Build from config to ensure classifier head dims match num_labels\n",
        "        config = AutoConfig.from_pretrained(self.cfg.model_id, num_labels=num_labels)\n",
        "        model = AutoModelForSequenceClassification.from_config(config)\n",
        "        state = self._load_state_dict_from_path(file_path)\n",
        "        missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "        if missing or unexpected:\n",
        "            print(\"[Single-file load] missing:\", missing, \"unexpected:\", unexpected)\n",
        "        return model, tok\n",
        "\n",
        "    def _build_teacher_any(self, num_labels: int) -> Tuple[torch.nn.Module, AutoTokenizer, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Main entry: returns (model, tokenizer, origin_path_for_size_measurement)\n",
        "        origin_path is used to report checkpoint size if it’s a single file.\n",
        "        \"\"\"\n",
        "        p = self.cfg.weights_path\n",
        "        if self._is_dir(p):\n",
        "            if not self._has_config(p):\n",
        "                raise FileNotFoundError(f\"{p} is a folder but has no config.json\")\n",
        "            model, tok = self._build_from_folder_maybe_custom_weights(p, num_labels)\n",
        "            return model, tok, None  # folder size measured via save_pretrained later\n",
        "        else:\n",
        "            # single file path\n",
        "            model, tok = self._build_from_single_file(p, num_labels)\n",
        "            return model, tok, p\n",
        "\n",
        "    # ------------- Quant builders -------------\n",
        "    def _build_dynamic_int8_from_model(self, model_fp: torch.nn.Module) -> torch.nn.Module:\n",
        "        if not (_HAS_AO_Q or _HAS_LEGACY_Q):\n",
        "            raise RuntimeError(\"torch dynamic quantization not available in this environment.\")\n",
        "        model_fp.eval().to(\"cpu\")\n",
        "        quantize_fn = ao_quantize_dynamic if _HAS_AO_Q else legacy_quantize_dynamic\n",
        "        q_model = quantize_fn(model_fp, {nn.Linear}, dtype=torch.qint8)\n",
        "        return q_model\n",
        "\n",
        "    def _build_bnb_from_model_via_tmp(self, model_fp: torch.nn.Module, num_labels: int) -> torch.nn.Module:\n",
        "        \"\"\"\n",
        "        Save FP model to a temp HF folder and reload with bnb 8-bit to stream weights safely.\n",
        "        \"\"\"\n",
        "        if not BNB_AVAILABLE:\n",
        "            raise RuntimeError(\"bitsandbytes not available; install it or set do_quantized=False.\")\n",
        "        tmpdir = tempfile.mkdtemp(prefix=\"tmp_ckpt_\")\n",
        "        try:\n",
        "            model_fp.save_pretrained(tmpdir, safe_serialization=True)\n",
        "            bnb_cfg = BitsAndBytesConfig(load_in_8bit=True)\n",
        "            q_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                tmpdir, quantization_config=bnb_cfg, device_map=\"auto\"\n",
        "            )\n",
        "        finally:\n",
        "            shutil.rmtree(tmpdir, ignore_errors=True)\n",
        "        return q_model\n",
        "\n",
        "    # ------------- Metrics / Eval -------------\n",
        "    def _count_params(self, model: torch.nn.Module) -> int:\n",
        "        return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _count_nonzero_params(self, model: torch.nn.Module) -> int:\n",
        "        nz = 0\n",
        "        for p in model.parameters():\n",
        "            if p is not None:\n",
        "                nz += (p != 0).sum().item()\n",
        "        return nz\n",
        "\n",
        "    def _to_device(self, batch: Dict[str, torch.Tensor], device: str) -> Dict[str, torch.Tensor]:\n",
        "        return {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    def _build_batches(self, tokenizer, texts: List[str]):\n",
        "        for i in range(0, len(texts), self.cfg.batch_size):\n",
        "            enc = tokenizer(\n",
        "                texts[i:i+self.cfg.batch_size],\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=self.cfg.max_len,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            yield enc\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _evaluate(self, model, tokenizer, texts, labels, device_override: Optional[str] = None):\n",
        "        from sklearn.metrics import f1_score\n",
        "        # Decide device per run\n",
        "        if device_override is not None:\n",
        "            run_device = device_override\n",
        "        elif self.cfg.force_cpu_for_all:\n",
        "            run_device = \"cpu\"\n",
        "        else:\n",
        "            run_device = self.device\n",
        "\n",
        "        # dynamic-quantized modules must stay on CPU\n",
        "        if any(\"Quantized\" in type(m).__name__ for m in model.modules()):\n",
        "            run_device = \"cpu\"\n",
        "\n",
        "        # bnb models already placed by device_map; avoid moving them\n",
        "        if not getattr(model, \"is_loaded_in_8bit\", False):\n",
        "            model.to(run_device)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Warmup\n",
        "        if texts:\n",
        "            enc = tokenizer(texts[:min(8, len(texts))], truncation=True, padding=True,\n",
        "                            max_length=self.cfg.max_len, return_tensors=\"pt\")\n",
        "            enc = self._to_device(enc, run_device)\n",
        "            if run_device == \"cuda\":\n",
        "                with torch.autocast(device_type=\"cuda\", dtype=self.amp_dtype):\n",
        "                    _ = model(**enc)\n",
        "            else:\n",
        "                _ = model(**enc)\n",
        "\n",
        "        preds_all = []\n",
        "        for i in range(0, len(texts), self.cfg.batch_size):\n",
        "            enc = tokenizer(texts[i:i+self.cfg.batch_size], truncation=True, padding=True,\n",
        "                            max_length=self.cfg.max_len, return_tensors=\"pt\")\n",
        "            enc = self._to_device(enc, run_device)\n",
        "\n",
        "            if run_device == \"cuda\":\n",
        "                torch.cuda.synchronize()\n",
        "                t0 = time.time()\n",
        "                with torch.autocast(device_type=\"cuda\", dtype=self.amp_dtype):\n",
        "                    logits = model(**enc).logits\n",
        "                torch.cuda.synchronize()\n",
        "            else:\n",
        "                t0 = time.time()\n",
        "                logits = model(**enc).logits\n",
        "\n",
        "            preds_all.append(torch.argmax(logits, dim=-1).cpu().numpy())\n",
        "\n",
        "        preds_all = np.concatenate(preds_all) if preds_all else np.array([])\n",
        "        labels = np.array(labels[:len(preds_all)])\n",
        "        acc = float((preds_all == labels).mean()) if len(preds_all) else float(\"nan\")\n",
        "        try:\n",
        "            f1 = float(f1_score(labels, preds_all, average=\"weighted\")) if len(preds_all) else float(\"nan\")\n",
        "        except Exception:\n",
        "            f1 = float(\"nan\")\n",
        "        return acc, f1\n",
        "\n",
        "    # ------------- Transformations -------------\n",
        "    def _apply_pruning(self, model: torch.nn.Module, amount: float):\n",
        "        if not PRUNE_AVAILABLE:\n",
        "            raise RuntimeError(\"torch pruning utilities not available.\")\n",
        "        linear_modules = []\n",
        "        for _, m in model.named_modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                linear_modules.append(m)\n",
        "        params_to_prune = [(m, \"weight\") for m in linear_modules]\n",
        "        prune.global_unstructured(\n",
        "            params_to_prune,\n",
        "            pruning_method=prune.L1Unstructured,\n",
        "            amount=amount,\n",
        "        )\n",
        "        # bake masks\n",
        "        for m in linear_modules:\n",
        "            try:\n",
        "                prune.remove(m, \"weight\")\n",
        "            except Exception:\n",
        "                pass\n",
        "        return model\n",
        "\n",
        "    # ------------- KD -------------\n",
        "    def _run_kd(self, teacher_model, tokenizer_t, train_df, test_df, num_labels):\n",
        "        from torch.utils.data import DataLoader, Dataset\n",
        "        from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "        class DS(Dataset):\n",
        "            def __init__(self, df, tok, max_len):\n",
        "                self.texts = df[\"text\"].tolist()\n",
        "                self.labels = df[\"label\"].tolist()\n",
        "                self.tok = tok\n",
        "                self.max_len = max_len\n",
        "            def __len__(self): return len(self.texts)\n",
        "            def __getitem__(self, i):\n",
        "                enc = self.tok(self.texts[i], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
        "                item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "                item[\"labels\"] = torch.tensor(self.labels[i], dtype=torch.long)\n",
        "                return item\n",
        "\n",
        "        teacher = teacher_model.to(self.device).eval()\n",
        "        teacher.requires_grad_(False)\n",
        "\n",
        "        s_tok = AutoTokenizer.from_pretrained(self.cfg.kd_student_id)\n",
        "        student = AutoModelForSequenceClassification.from_pretrained(\n",
        "            self.cfg.kd_student_id, num_labels=num_labels\n",
        "        ).to(self.device)\n",
        "\n",
        "        train_loader = DataLoader(DS(train_df, s_tok, self.cfg.max_len), batch_size=32, shuffle=True)\n",
        "        T = self.cfg.kd_T; alpha = self.cfg.kd_alpha\n",
        "        optim = torch.optim.AdamW(student.parameters(), lr=3e-5)\n",
        "        sched = get_linear_schedule_with_warmup(optim, 0, self.cfg.kd_epochs*len(train_loader))\n",
        "\n",
        "        student.train()\n",
        "        for _ in range(self.cfg.kd_epochs):\n",
        "            for batch in train_loader:\n",
        "                optim.zero_grad(set_to_none=True)\n",
        "                ids = batch[\"input_ids\"].to(self.device)\n",
        "                msk = batch[\"attention_mask\"].to(self.device)\n",
        "                y   = batch[\"labels\"].to(self.device)\n",
        "\n",
        "                s_logits = student(input_ids=ids, attention_mask=msk).logits\n",
        "                with torch.no_grad():\n",
        "                    texts_batch = s_tok.batch_decode(ids, skip_special_tokens=True)\n",
        "                    t_enc = tokenizer_t(\n",
        "                        texts_batch, truncation=True, padding=True,\n",
        "                        max_length=self.cfg.max_len, return_tensors=\"pt\"\n",
        "                    )\n",
        "                    t_enc = {k: v.to(self.device) for k, v in t_enc.items()}\n",
        "                    t_logits = teacher(**t_enc).logits\n",
        "\n",
        "                log_p_s = F.log_softmax(s_logits / T, dim=-1)\n",
        "                p_t     = F.softmax(t_logits / T, dim=-1)\n",
        "                loss_kd = F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T*T)\n",
        "                loss_ce = F.cross_entropy(s_logits, y)\n",
        "                loss = alpha * loss_kd + (1 - alpha) * loss_ce\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(student.parameters(), 1.0)\n",
        "                optim.step(); sched.step()\n",
        "\n",
        "        acc, f1 = self._evaluate(student, s_tok, test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
        "        return student, acc, f1\n",
        "\n",
        "    # ------------- Public run -------------\n",
        "    def run(self, test_df, train_df: Optional[object] = None):\n",
        "        import pandas as pd\n",
        "        assert {\"text\", \"label\"}.issubset(test_df.columns), \"test_df must have columns: text, label\"\n",
        "        num_labels = self.cfg.num_labels or int(test_df[\"label\"].nunique())\n",
        "\n",
        "        # --- Build teacher/original from folder-or-file (NEW core path) ---\n",
        "        orig_model, tok, single_file_origin = self._build_teacher_any(num_labels)\n",
        "        orig_model = orig_model.to(self.device).eval()\n",
        "\n",
        "        rows = []\n",
        "\n",
        "        # Evaluate Original\n",
        "        acc_o, f1_o = self._evaluate(orig_model, tok, test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
        "        params_o = self._count_params(orig_model)\n",
        "\n",
        "        # Size reporting:\n",
        "        # - If we loaded from a single file: report that file size.\n",
        "        # - If we loaded from a folder: serialize to temp folder for consistent measurement.\n",
        "        if single_file_origin is not None:\n",
        "            orig_ckpt_mb = self._file_size_mb(single_file_origin)\n",
        "        else:\n",
        "            orig_ckpt_mb = self._save_pretrained_and_measure_mb(orig_model)\n",
        "\n",
        "        rows.append({\n",
        "            \"Model\": \"Original (FP)\",\n",
        "            \"Requires Training\": False,\n",
        "            \"Params (M)\": round(params_o/1e6, 2),\n",
        "            \"Nonzero Params (M)\": round(params_o/1e6, 2),\n",
        "            \"Accuracy\": round(acc_o, 4),\n",
        "            \"F1 (weighted)\": round(f1_o, 4),\n",
        "            \"Checkpoint Size (MB)\": round(orig_ckpt_mb, 2) if orig_ckpt_mb is not None else None,\n",
        "        })\n",
        "\n",
        "        # Quantized (8-bit)\n",
        "        if self.cfg.do_quantized:\n",
        "            if self.cfg.quantization_backend == \"dynamic\":\n",
        "                q = self._build_dynamic_int8_from_model(orig_model)\n",
        "                acc_q, f1_q = self._evaluate(q, tok, test_df[\"text\"].tolist(), test_df[\"label\"].tolist(), device_override=\"cpu\")\n",
        "                # Param count equals FP architecture param count\n",
        "                params_q = self._count_params(\n",
        "                    AutoModelForSequenceClassification.from_pretrained(self.cfg.model_id, num_labels=num_labels)\n",
        "                )\n",
        "                q_ckpt_mb = self._save_state_dict_and_measure_mb(q)  # dynamic quant: measure via state_dict\n",
        "                rows.append({\n",
        "                    \"Model\": \"8-bit Quantized (dynamic, CPU)\",\n",
        "                    \"Requires Training\": False,\n",
        "                    \"Params (M)\": round(params_q/1e6, 2),\n",
        "                    \"Nonzero Params (M)\": round(params_q/1e6, 2),\n",
        "                    \"Accuracy\": round(acc_q, 4),\n",
        "                    \"F1 (weighted)\": round(f1_q, 4),\n",
        "                    \"Checkpoint Size (MB)\": round(q_ckpt_mb, 2) if q_ckpt_mb is not None else None,\n",
        "                })\n",
        "\n",
        "            elif self.cfg.quantization_backend == \"bnb\":\n",
        "                q = self._build_bnb_from_model_via_tmp(orig_model, num_labels)\n",
        "                acc_q, f1_q = self._evaluate(q, tok, test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
        "                params_q = self._count_params(q)\n",
        "                # save_pretrained may serialize dequantized weights; still useful to log.\n",
        "                q_ckpt_mb = self._save_pretrained_and_measure_mb(q)\n",
        "                rows.append({\n",
        "                    \"Model\": \"8-bit Quantized (bnb, GPU)\",\n",
        "                    \"Requires Training\": False,\n",
        "                    \"Params (M)\": round(params_q/1e6, 2),\n",
        "                    \"Nonzero Params (M)\": round(params_q/1e6, 2),\n",
        "                    \"Accuracy\": round(acc_q, 4),\n",
        "                    \"F1 (weighted)\": round(f1_q, 4),\n",
        "                    \"Checkpoint Size (MB)\": round(q_ckpt_mb, 2),\n",
        "                })\n",
        "            else:\n",
        "                raise ValueError(\"quantization_backend must be 'dynamic' or 'bnb'\")\n",
        "\n",
        "        # Pruned (no FT)\n",
        "        if self.cfg.do_pruned:\n",
        "            pr = AutoModelForSequenceClassification.from_pretrained(\n",
        "                self.cfg.model_id, num_labels=num_labels, ignore_mismatched_sizes=True\n",
        "            )\n",
        "            # Load the same weights into the fresh FP model (ensures clean copy before pruning)\n",
        "            if self._is_dir(self.cfg.weights_path) and self._has_config(self.cfg.weights_path):\n",
        "                wpath = self._find_weight_file_in_dir(self.cfg.weights_path)\n",
        "                if wpath and not any(os.path.basename(wpath) == s for s in [\"pytorch_model.bin\", \"model.safetensors\"]):\n",
        "                    # custom filename in folder -> use state_dict\n",
        "                    state = self._load_state_dict_from_path(wpath)\n",
        "                    pr.load_state_dict(state, strict=False)\n",
        "                else:\n",
        "                    # standard HF folder -> load via from_pretrained directly above? (We already built new pr from base model_id)\n",
        "                    # Reload from folder to be exact:\n",
        "                    pr = AutoModelForSequenceClassification.from_pretrained(\n",
        "                        self.cfg.weights_path, num_labels=num_labels, ignore_mismatched_sizes=True\n",
        "                    )\n",
        "            else:\n",
        "                # single file case\n",
        "                state = self._load_state_dict_from_path(self.cfg.weights_path)\n",
        "                pr.load_state_dict(state, strict=False)\n",
        "\n",
        "            pr = self._apply_pruning(pr, self.cfg.prune_amount).to(self.device).eval()\n",
        "            acc_p, f1_p = self._evaluate(pr, tok, test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
        "            params_p = self._count_params(pr)\n",
        "            nonzero_p = self._count_nonzero_params(pr)\n",
        "            p_ckpt_mb = self._save_pretrained_and_measure_mb(pr)\n",
        "            rows.append({\n",
        "                \"Model\": f\"Pruned ({int(self.cfg.prune_amount*100)}% target, no FT)\",\n",
        "                \"Requires Training\": False,\n",
        "                \"Params (M)\": round(params_p/1e6, 2),\n",
        "                \"Nonzero Params (M)\": round(nonzero_p/1e6, 2),\n",
        "                \"Accuracy\": round(acc_p, 4),\n",
        "                \"F1 (weighted)\": round(f1_p, 4),\n",
        "                \"Checkpoint Size (MB)\": round(p_ckpt_mb, 2),\n",
        "            })\n",
        "\n",
        "        # KD Student (optional)\n",
        "        if self.cfg.do_kd:\n",
        "            if (train_df is None) or (not {\"text\",\"label\"}.issubset(train_df.columns)):\n",
        "                rows.append({\n",
        "                    \"Model\": f\"KD Student ({self.cfg.kd_student_id})\",\n",
        "                    \"Requires Training\": True,\n",
        "                    \"Params (M)\": None, \"Nonzero Params (M)\": None,\n",
        "                    \"Accuracy\": None, \"F1 (weighted)\": None, \"Checkpoint Size (MB)\": None\n",
        "                })\n",
        "            else:\n",
        "                student, acc_kd, f1_kd = self._run_kd(orig_model, tok, train_df, test_df, num_labels)\n",
        "                params_kd = self._count_params(student)\n",
        "                kd_ckpt_mb = self._save_pretrained_and_measure_mb(student)\n",
        "                rows.append({\n",
        "                    \"Model\": f\"KD Student ({self.cfg.kd_student_id})\",\n",
        "                    \"Requires Training\": True,\n",
        "                    \"Params (M)\": round(params_kd/1e6, 2),\n",
        "                    \"Nonzero Params (M)\": round(params_kd/1e6, 2),\n",
        "                    \"Accuracy\": round(acc_kd, 4),\n",
        "                    \"F1 (weighted)\": round(f1_kd, 4),\n",
        "                    \"Checkpoint Size (MB)\": round(kd_ckpt_mb, 2),\n",
        "                })\n",
        "\n",
        "        df = __import__(\"pandas\").DataFrame(rows)\n",
        "\n",
        "        # Convenience print if original was a single file path\n",
        "        if self._is_dir(self.cfg.weights_path):\n",
        "            print(f\"\\nLoaded from folder: {self.cfg.weights_path}\")\n",
        "        else:\n",
        "            ckpt_mb = self._file_size_mb(self.cfg.weights_path)\n",
        "            if ckpt_mb is not None:\n",
        "                print(f\"\\nOriginal checkpoint file size: {ckpt_mb:.2f} MB\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "4s8-LF3CG4ax"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Original Data\n",
        "## No need for other datasets since best models were achieved for original training data"
      ],
      "metadata": {
        "id": "aA4eRlB4HwcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/ADV_DL/Data\"\n",
        "train_df = pd.read_csv(f\"{DATA_DIR}/Corona_NLP_train.csv\", encoding=\"latin-1\")\n",
        "test_df  = pd.read_csv(f\"{DATA_DIR}/Corona_NLP_test.csv\",  encoding=\"latin-1\")\n",
        "\n",
        "train_df = train_df.rename(columns={\"OriginalTweet\":\"text\", \"Sentiment\":\"label\"})\n",
        "test_df  = test_df.rename(columns={\"OriginalTweet\":\"text\", \"Sentiment\":\"label\"})\n",
        "\n",
        "label_map = {'Extremely Negative':0,'Negative':1,'Neutral':2,\n",
        "             'Positive':3,'Extremely Positive':4}\n",
        "\n",
        "train_df[\"label\"] = train_df.label.map(label_map).astype(int)\n",
        "test_df[\"label\"]  = test_df.label.map(label_map).astype(int)"
      ],
      "metadata": {
        "id": "XJ4CS_kyH7Lh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Full-Code Fine-Tuned DeBERTa-v3-base"
      ],
      "metadata": {
        "id": "TVgKFr9W_w69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"CarmelKron/Model_Checkpoints\"\n",
        "subdir  = \"full_ft_deberta_v3_base\"  # the folder inside the repo\n",
        "\n",
        "repo_dir = snapshot_download(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        "    allow_patterns=[f\"{subdir}/*\"],  # only pull this folder\n",
        "    # optional: local_dir=\"checkpoints_cache\", local_dir_use_symlinks=False,\n",
        ")\n",
        "\n",
        "folder_path = str(Path(repo_dir) / subdir)  # <- this contains config.json + best_model.pt\n",
        "print(\"Folder path:\", folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "91ad11a4a23241dab2de072734727a43",
            "be1a608b45534d44b1ecc590615832cc",
            "a151eba1d2ef4b49868af284477847be",
            "10fbb2a652474e519148ff3d356f5c1d",
            "ade1c71e054f47f5a25a3d272894d548",
            "8b597cf6d6b54085b9c12f497f35779c",
            "f771ce1d2dba4a5a90c0c6c522678109",
            "236a99239b4b480c8da16b46b8d9f1a1",
            "f7baf5b14d45465b923fe23636265a71",
            "93e9423a8ce242678691cd109fa708bd",
            "c88a4a85483547488884fd38306e7066",
            "42c52558d20445f595fb33e22a4e2675",
            "272684a539664820abc4d3f1cbced5df",
            "b9c7296c93454cb2b225523a669645dc",
            "f05acc876d9741e39ab2685c6d1d1a92",
            "b449721a02434b85b8b087b338dfb2df",
            "da335b0cab1b42c595f934627b16ddd3",
            "468a0fdd675d4324ad5d967392fe4bb5",
            "c0bb55f07f4242789beb59f1574b5512",
            "3a497b35de9a4a7fa216d5bdda01157b",
            "761cfc6a7a5043de971df22f6ad82acf",
            "e6e94163dda24fba8ed69d1bffc8c3ff"
          ]
        },
        "id": "X7mv2tazGigb",
        "outputId": "1d68c5db-8fe4-4559-a5d0-15161a4a57c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91ad11a4a23241dab2de072734727a43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42c52558d20445f595fb33e22a4e2675"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder path: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/full_ft_deberta_v3_base\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = CompressConfig(\n",
        "    model_id=\"microsoft/deberta-v3-base\",\n",
        "    weights_path=folder_path,   # <— key change\n",
        "    num_labels=None,            # infer from test_df\n",
        "    max_len=64,\n",
        "    batch_size=32,\n",
        "    prune_amount=0.4,\n",
        "    do_quantized=True,\n",
        "    do_pruned=True,\n",
        "    do_kd=True,                 # set True and pass train_df to actually train KD\n",
        "    quantization_backend=\"bnb\",\n",
        "    force_cpu_for_all=False\n",
        ")\n",
        "\n",
        "cmp = CompressionComparator(cfg)\n",
        "results = cmp.run(test_df=test_df, train_df=train_df)\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "id": "WaqlwfOIKJoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e11929-f677-41a6-ca06-b94ce566364d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded from folder: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/full_ft_deberta_v3_base\n",
            "                               Model  Requires Training  Params (M)  Nonzero Params (M)  Accuracy  F1 (weighted)  Checkpoint Size (MB)\n",
            "                       Original (FP)              False      184.43              184.43    0.7038         0.7043                703.55\n",
            "          8-bit Quantized (bnb, GPU)              False      184.43              184.43    0.7156         0.7169                270.69\n",
            "          Pruned (40% target, no FT)              False      184.43              150.20    0.7109         0.7122                703.55\n",
            "KD Student (distilbert-base-uncased)               True       66.96               66.96    0.7962         0.7967                255.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: HF Fine-Tuned DeBERTa-v3-base"
      ],
      "metadata": {
        "id": "Pqx-G_EpOZJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"CarmelKron/Model_Checkpoints\"\n",
        "subdir  = \"hf_ft_deberta_v3_base_orig\"  # the folder inside the repo\n",
        "\n",
        "repo_dir = snapshot_download(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        "    allow_patterns=[f\"{subdir}/*\"],  # only pull this folder\n",
        "    # optional: local_dir=\"checkpoints_cache\", local_dir_use_symlinks=False,\n",
        ")\n",
        "\n",
        "folder_path = str(Path(repo_dir) / subdir)  # <- this contains config.json + best_model.pt\n",
        "print(\"Folder path:\", folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "638b17c581f247b5a3e9dd5a7576d0df",
            "ad2cccbd76f045d293e469803d6dd4fd",
            "77e393772c144a0f9deadb3d64571c6e",
            "88332f787895410e88f6f6c33f67f169",
            "be7d27cab0144dd597b6547487721e7b",
            "bbb965a57de04d8a8ef33c7ce6325667",
            "ba686b582e8b40789aab1e4867356cbe",
            "2fe2905ef0a4460ab34c83b25f6313a2",
            "e25ea8aa3ddf4262aa659324158004c2",
            "84ea377db7754699bc9728e3238f502b",
            "58b99f37814c4b7abdd285e49159c516"
          ]
        },
        "id": "4GT17bc2hip_",
        "outputId": "69c1b1f3-0b21-4387-e7ef-03f4faf5b89b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "638b17c581f247b5a3e9dd5a7576d0df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder path: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/hf_ft_deberta_v3_base_orig\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = CompressConfig(\n",
        "    model_id=\"microsoft/deberta-v3-base\",\n",
        "    weights_path=folder_path,   # <— key change\n",
        "    num_labels=None,            # infer from test_df\n",
        "    max_len=128,\n",
        "    batch_size=32,\n",
        "    prune_amount=0.4,\n",
        "    do_quantized=True,\n",
        "    do_pruned=True,\n",
        "    do_kd=True,                 # set True and pass train_df to actually train KD\n",
        "    quantization_backend=\"bnb\",\n",
        "    force_cpu_for_all=False\n",
        ")\n",
        "\n",
        "cmp = CompressionComparator(cfg)\n",
        "results = cmp.run(test_df=test_df, train_df=train_df)\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0ENUJtlhiqB",
        "outputId": "625ffd17-37d3-4c0b-f178-7e1811bd32d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded from folder: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/hf_ft_deberta_v3_base_orig\n",
            "                               Model  Requires Training  Params (M)  Nonzero Params (M)  Accuracy  F1 (weighted)  Checkpoint Size (MB)\n",
            "                       Original (FP)              False      184.43              184.43    0.8702         0.8700                703.55\n",
            "          8-bit Quantized (bnb, GPU)              False      184.43              184.43    0.8689         0.8687                270.69\n",
            "          Pruned (40% target, no FT)              False      184.43              150.21    0.8346         0.8333                703.55\n",
            "KD Student (distilbert-base-uncased)               True       66.96               66.96    0.8162         0.8164                255.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Full-Code Fine-Tuned Twitter-RoBERTa"
      ],
      "metadata": {
        "id": "Z9X9YZ3lHkyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"CarmelKron/Model_Checkpoints\"\n",
        "subdir  = \"full_ft_twitter_roberta\"  # the folder inside the repo\n",
        "\n",
        "repo_dir = snapshot_download(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        "    allow_patterns=[f\"{subdir}/*\"],  # only pull this folder\n",
        "    # optional: local_dir=\"checkpoints_cache\", local_dir_use_symlinks=False,\n",
        ")\n",
        "\n",
        "folder_path = str(Path(repo_dir) / subdir)  # <- this contains config.json + best_model.pt\n",
        "print(\"Folder path:\", folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "dd18220e80b740e08193aa8fed8d7d7e",
            "4a973a0418e5455790434be854fa25d9",
            "224b80985ed74650abec60e2ceea4035",
            "5164ae0c850e4aaeaf41fe5f13acca29",
            "0f14da2276d740219c9102dc9f42d0f0",
            "5d835b37925d44aea7f611ce362c385b",
            "7d195d8836864fb1b1267b3a96bc6407",
            "725c6063f3374d7a9239d7db0cf52d6b",
            "b257f597f27e4dddaf5269c15306b4b0",
            "13b7a969f2da4550b97b031fdec16de7",
            "d2013a94766841868f3d0ed2f3f2efc1"
          ]
        },
        "id": "y2eGAZZ-hv0T",
        "outputId": "e06567e8-cbb4-4dfe-d22a-817234d072eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd18220e80b740e08193aa8fed8d7d7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder path: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/full_ft_twitter_roberta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = CompressConfig(\n",
        "    model_id=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    weights_path=folder_path,   # <— key change\n",
        "    num_labels=None,            # infer from test_df\n",
        "    max_len=128,\n",
        "    batch_size=32,\n",
        "    prune_amount=0.4,\n",
        "    do_quantized=True,\n",
        "    do_pruned=True,\n",
        "    do_kd=True,                 # set True and pass train_df to actually train KD\n",
        "    quantization_backend=\"bnb\",\n",
        "    force_cpu_for_all=False\n",
        ")\n",
        "\n",
        "cmp = CompressionComparator(cfg)\n",
        "results = cmp.run(test_df=test_df, train_df=train_df)\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl-2seZXhv0T",
        "outputId": "982645dc-5f7d-4979-9153-5358a7fe86ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded from folder: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/full_ft_twitter_roberta\n",
            "                               Model  Requires Training  Params (M)  Nonzero Params (M)  Accuracy  F1 (weighted)  Checkpoint Size (MB)\n",
            "                       Original (FP)              False      124.65              124.65    0.6438         0.6466                475.52\n",
            "          8-bit Quantized (bnb, GPU)              False      124.65              124.65    0.6477         0.6507                156.67\n",
            "          Pruned (40% target, no FT)              False      124.65               90.44    0.3765         0.3059                475.52\n",
            "KD Student (distilbert-base-uncased)               True       66.96               66.96    0.8004         0.8008                255.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: HF Fine-Tuned Twitter-RoBERTa"
      ],
      "metadata": {
        "id": "1viDX1aFJDHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"CarmelKron/Model_Checkpoints\"\n",
        "subdir  = \"hf_ft_twitter_roberta_orig\"  # the folder inside the repo\n",
        "\n",
        "repo_dir = snapshot_download(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        "    allow_patterns=[f\"{subdir}/*\"],  # only pull this folder\n",
        "    # optional: local_dir=\"checkpoints_cache\", local_dir_use_symlinks=False,\n",
        ")\n",
        "\n",
        "folder_path = str(Path(repo_dir) / subdir)  # <- this contains config.json + best_model.pt\n",
        "print(\"Folder path:\", folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1e1d0516c7324378b471aeecd50e8b56",
            "de92d7edb59749fdacf15ce8fd61a18f",
            "ceb8dfc0a9374360bbd45d7dc5d0d6b3",
            "5997fa1ba794499fb820360e3076655c",
            "fd5fafc429d6467e9d98caa9ae0ad00d",
            "1f24edc978c04457928274fc039d416a",
            "953f7b4c431d412b9c075951114f1ead",
            "9847f40287d34f3e830f7fc78d526eaa",
            "e4f7d40a10b245bcab8d88d253009e29",
            "0e838efed1864eac88869e02aceddd58",
            "ac19118900e5466fa14a5d8d9d0a4b20"
          ]
        },
        "id": "qw6ecTlBh41k",
        "outputId": "53319610-2fe3-4651-8792-765825eb1016"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e1d0516c7324378b471aeecd50e8b56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder path: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/hf_ft_twitter_roberta_orig\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = CompressConfig(\n",
        "    model_id=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    weights_path=folder_path,   # <— key change\n",
        "    num_labels=None,            # infer from test_df\n",
        "    max_len=254,\n",
        "    batch_size=32,\n",
        "    prune_amount=0.4,\n",
        "    do_quantized=True,\n",
        "    do_pruned=True,\n",
        "    do_kd=True,                 # set True and pass train_df to actually train KD\n",
        "    quantization_backend=\"bnb\",\n",
        "    force_cpu_for_all=False\n",
        ")\n",
        "\n",
        "cmp = CompressionComparator(cfg)\n",
        "results = cmp.run(test_df=test_df, train_df=train_df)\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRPgAOGrh41l",
        "outputId": "b645e915-0093-4efc-d7a4-00cd185b0040"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded from folder: /root/.cache/huggingface/hub/models--CarmelKron--Model_Checkpoints/snapshots/51639b8e812643cdc286534a504ca5d5deb7ef91/hf_ft_twitter_roberta_orig\n",
            "                               Model  Requires Training  Params (M)  Nonzero Params (M)  Accuracy  F1 (weighted)  Checkpoint Size (MB)\n",
            "                       Original (FP)              False      124.65              124.65    0.8589         0.8589                475.52\n",
            "          8-bit Quantized (bnb, GPU)              False      124.65              124.65    0.8610         0.8611                156.67\n",
            "          Pruned (40% target, no FT)              False      124.65               90.44    0.7562         0.7431                475.52\n",
            "KD Student (distilbert-base-uncased)               True       66.96               66.96    0.8254         0.8256                255.43\n"
          ]
        }
      ]
    }
  ]
}